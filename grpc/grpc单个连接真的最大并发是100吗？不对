æµ‹è¯•ä»£ç 
æœåŠ¡ç«¯ï¼š
package main

import (
	"context"
	"errors"
	"fmt"
	"math/rand"
	"time"

	"github.com/95933447/grpcgateway/example/client/echo"
	"github.com/995933447/microgosuit"
	"github.com/995933447/microgosuit/discovery"
	"github.com/995933447/microgosuit/grpcsuit"
	"google.golang.org/grpc"
)

func main() {
	err := microgosuit.InitSuitWithGrpc(context.TODO(), "../meta.json", "testschema", "test_discovery")
	if err != nil {
		panic(err)
	}

	err = microgosuit.ServeGrpc(context.TODO(), &microgosuit.ServeGrpcReq{
		RegDiscoverKeyPrefix: "test_discovery",
		SrvName:              "echo.Echo",
		IpVar:                "$inner_ip",
		Port:                 9111,
		RegisterCustomServiceServerFunc: func(server *grpc.Server) error {
			echo.RegisterEchoServer(server, &EchoService{})
			return nil
		},
		AfterRegDiscover: func(discovery discovery.Discovery, node *discovery.Node) error {
			fmt.Printf("======\nrun echo service success.\nhost:%s\nprot:%d\n======\n", node.Host, node.Port)
			return nil
		},
	})
	if err != nil {
		panic(err)
	}
}

type EchoService struct {
	echo.UnimplementedEchoServer
}

func (s *EchoService) BasicEcho(ctx context.Context, req *echo.EchoReq) (*echo.EchoResp, error) {
	var resp echo.EchoResp
	time.Sleep(time.Second)
	resp.Echo = req.Echo
	return &resp, nil
}

func (s *EchoService) InnerEcho(ctx context.Context, req *echo.EchoReq) (*echo.EchoResp, error) {
	return s.BasicEcho(ctx, req)
}

func (s *EchoService) NoAuthEcho(ctx context.Context, req *echo.EchoReq) (*echo.EchoResp, error) {
	return s.BasicEcho(ctx, req)
}

func (s *EchoService) NoAuthEchoErr(ctx context.Context, req *echo.EchoReq) (*echo.EchoResp, error) {
	r := rand.Intn(100)
	if r > 50 {
		return nil, errors.New("sys err")
	}
	return nil, grpcsuit.NewRpcErr(echo.ErrCode_ErrFail)
}


æµ‹è¯•å®¢æˆ·ç«¯ä»£ç :
package main

import (
	"context"
	"sync"
	"testing"
	"time"

	"github.com/95933447/grpcgateway/example/client/echo"
	"google.golang.org/grpc"
)

func TestBenchEcho(t *testing.T) {
	conn, err := grpc.NewClient("192.168.2.225:9111", grpc.WithInsecure())
	if err != nil {
		panic(err)
	}

	start := time.Now()
	var wg sync.WaitGroup
	for i := 0; i < 10000; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			_, err = echo.NewEchoClient(conn).BasicEcho(context.TODO(), &echo.EchoReq{
				Echo: "hello world",
			})
			if err != nil {
				panic(err)
			}
		}()
	}
	wg.Wait()

	// 10000å¹¶å‘ time elapsed: 1.188055666s æ‰€ä»¥grpcçš„å•ä¸ªæµçš„æœ€å¤§å¹¶å‘é™åˆ¶é»˜è®¤ä¸æ˜¯å¦‚ç½‘ä¸Šæ‰€è¯´çš„100
	t.Logf("time elapsed: %s\n", time.Since(start))
}

ï¼ˆgoogle.golang.org/grpcï¼‰æœåŠ¡ç«¯é»˜è®¤ SETTINGS_MAX_CONCURRENT_STREAMS æ˜¯ 2Â¹â¶âˆ’1ï¼ˆ65535ï¼‰ã€‚
ğŸ‘‰ ä¹Ÿå°±æ˜¯è¯´ï¼š

å¹¶ä¸æ˜¯ 100ï¼Œè€Œæ˜¯ 65535 ä¸ª stream å¯ä»¥åŒæ—¶å¹¶å‘ã€‚

æ‰€ä»¥ 10000 ä¸ªè¯·æ±‚å…¨éƒ¨åŒæ—¶è·‘èµ·æ¥äº†ã€‚
åœ¨ gRPC-Go çš„å®ç°é‡Œï¼š

æœåŠ¡ç«¯é»˜è®¤ grpc.MaxConcurrentStreams = math.MaxUint32 (â‰ˆ 4 billion)ï¼Œä½†å®é™…å— HTTP/2 è§„èŒƒé™åˆ¶ï¼Œæœ€ç»ˆå‘ç»™å®¢æˆ·ç«¯çš„å€¼æ˜¯ 65535ã€‚

å®¢æˆ·ç«¯åªéµå®ˆæœåŠ¡ç«¯ä¸‹å‘çš„ SETTINGS_MAX_CONCURRENT_STREAMSï¼Œå¹¶ä¸ä¼šè‡ªå·±é¢å¤–é™åˆ¶åˆ° 100ã€‚

å› æ­¤ï¼š

æ¯ä¸ªè¯·æ±‚ time.Sleep(1s) â†’ å…¨éƒ¨è¯·æ±‚å‡ ä¹åŒæ—¶å¼€å§‹ã€åŒæ—¶ç»“æŸã€‚

ç»“æœå°±æ˜¯ æ•´ä½“è€—æ—¶ â‰ˆ 1sã€‚

ä»æºç çœ‹å®¢æˆ·ç«¯è®¾ç½®äº†æœ€å¤§å¹¶å‘100ï¼Œä¸ºä»€ä¹ˆä¸ç”Ÿæ•ˆï¼Ÿ
å®¢æˆ·ç«¯æºç ï¼š
// NewHTTP2Client constructs a connected ClientTransport to addr based on HTTP2
// and starts to receive messages on it. Non-nil error returns if construction
// fails.
func NewHTTP2Client(connectCtx, ctx context.Context, addr resolver.Address, opts ConnectOptions, onClose func(GoAwayReason)) (_ ClientTransport, err error) {
	scheme := "http"
	ctx, cancel := context.WithCancel(ctx)
	defer func() {
		if err != nil {
			cancel()
		}
	}()

	// gRPC, resolver, balancer etc. can specify arbitrary data in the
	// Attributes field of resolver.Address, which is shoved into connectCtx
	// and passed to the dialer and credential handshaker. This makes it possible for
	// address specific arbitrary data to reach custom dialers and credential handshakers.
	connectCtx = icredentials.NewClientHandshakeInfoContext(connectCtx, credentials.ClientHandshakeInfo{Attributes: addr.Attributes})

	conn, err := dial(connectCtx, opts.Dialer, addr, opts.UserAgent)
	if err != nil {
		if opts.FailOnNonTempDialError {
			return nil, connectionErrorf(isTemporary(err), err, "transport: error while dialing: %v", err)
		}
		return nil, connectionErrorf(true, err, "transport: Error while dialing: %v", err)
	}

	// Any further errors will close the underlying connection
	defer func(conn net.Conn) {
		if err != nil {
			conn.Close()
		}
	}(conn)

	// The following defer and goroutine monitor the connectCtx for cancellation
	// and deadline.  On context expiration, the connection is hard closed and
	// this function will naturally fail as a result.  Otherwise, the defer
	// waits for the goroutine to exit to prevent the context from being
	// monitored (and to prevent the connection from ever being closed) after
	// returning from this function.
	ctxMonitorDone := grpcsync.NewEvent()
	newClientCtx, newClientDone := context.WithCancel(connectCtx)
	defer func() {
		newClientDone()         // Awaken the goroutine below if connectCtx hasn't expired.
		<-ctxMonitorDone.Done() // Wait for the goroutine below to exit.
	}()
	go func(conn net.Conn) {
		defer ctxMonitorDone.Fire() // Signal this goroutine has exited.
		<-newClientCtx.Done()       // Block until connectCtx expires or the defer above executes.
		if err := connectCtx.Err(); err != nil {
			// connectCtx expired before exiting the function.  Hard close the connection.
			if logger.V(logLevel) {
				logger.Infof("Aborting due to connect deadline expiring: %v", err)
			}
			conn.Close()
		}
	}(conn)

	kp := opts.KeepaliveParams
	// Validate keepalive parameters.
	if kp.Time == 0 {
		kp.Time = defaultClientKeepaliveTime
	}
	if kp.Timeout == 0 {
		kp.Timeout = defaultClientKeepaliveTimeout
	}
	keepaliveEnabled := false
	if kp.Time != infinity {
		if err = isyscall.SetTCPUserTimeout(conn, kp.Timeout); err != nil {
			return nil, connectionErrorf(false, err, "transport: failed to set TCP_USER_TIMEOUT: %v", err)
		}
		keepaliveEnabled = true
	}
	var (
		isSecure bool
		authInfo credentials.AuthInfo
	)
	transportCreds := opts.TransportCredentials
	perRPCCreds := opts.PerRPCCredentials

	if b := opts.CredsBundle; b != nil {
		if t := b.TransportCredentials(); t != nil {
			transportCreds = t
		}
		if t := b.PerRPCCredentials(); t != nil {
			perRPCCreds = append(perRPCCreds, t)
		}
	}
	if transportCreds != nil {
		conn, authInfo, err = transportCreds.ClientHandshake(connectCtx, addr.ServerName, conn)
		if err != nil {
			return nil, connectionErrorf(isTemporary(err), err, "transport: authentication handshake failed: %v", err)
		}
		for _, cd := range perRPCCreds {
			if cd.RequireTransportSecurity() {
				if ci, ok := authInfo.(interface {
					GetCommonAuthInfo() credentials.CommonAuthInfo
				}); ok {
					secLevel := ci.GetCommonAuthInfo().SecurityLevel
					if secLevel != credentials.InvalidSecurityLevel && secLevel < credentials.PrivacyAndIntegrity {
						return nil, connectionErrorf(true, nil, "transport: cannot send secure credentials on an insecure connection")
					}
				}
			}
		}
		isSecure = true
		if transportCreds.Info().SecurityProtocol == "tls" {
			scheme = "https"
		}
	}
	icwz := int32(initialWindowSize)
	if opts.InitialConnWindowSize >= defaultWindowSize {
		icwz = opts.InitialConnWindowSize
	}
	writeBufSize := opts.WriteBufferSize
	readBufSize := opts.ReadBufferSize
	maxHeaderListSize := defaultClientMaxHeaderListSize
	if opts.MaxHeaderListSize != nil {
		maxHeaderListSize = *opts.MaxHeaderListSize
	}

	t := &http2Client{
		ctx:                   ctx,
		ctxDone:               ctx.Done(), // Cache Done chan.
		cancel:                cancel,
		userAgent:             opts.UserAgent,
		registeredCompressors: grpcutil.RegisteredCompressors(),
		address:               addr,
		conn:                  conn,
		remoteAddr:            conn.RemoteAddr(),
		localAddr:             conn.LocalAddr(),
		authInfo:              authInfo,
		readerDone:            make(chan struct{}),
		writerDone:            make(chan struct{}),
		goAway:                make(chan struct{}),
		keepaliveDone:         make(chan struct{}),
		framer:                newFramer(conn, writeBufSize, readBufSize, opts.SharedWriteBuffer, maxHeaderListSize),
		fc:                    &trInFlow{limit: uint32(icwz)},
		scheme:                scheme,
		activeStreams:         make(map[uint32]*ClientStream),
		isSecure:              isSecure,
		perRPCCreds:           perRPCCreds,
		kp:                    kp,
		statsHandlers:         opts.StatsHandlers,
		initialWindowSize:     initialWindowSize,
		nextID:                1,
		maxConcurrentStreams:  defaultMaxStreamsClient,
		streamQuota:           defaultMaxStreamsClient,
		streamsQuotaAvailable: make(chan struct{}, 1),
		keepaliveEnabled:      keepaliveEnabled,
		bufferPool:            opts.BufferPool,
		onClose:               onClose,
	}
	var czSecurity credentials.ChannelzSecurityValue
	if au, ok := authInfo.(credentials.ChannelzSecurityInfo); ok {
		czSecurity = au.GetSecurityValue()
	}
	t.channelz = channelz.RegisterSocket(
		&channelz.Socket{
			SocketType:       channelz.SocketTypeNormal,
			Parent:           opts.ChannelzParent,
			SocketMetrics:    channelz.SocketMetrics{},
			EphemeralMetrics: t.socketMetrics,
			LocalAddr:        t.localAddr,
			RemoteAddr:       t.remoteAddr,
			SocketOptions:    channelz.GetSocketOption(t.conn),
			Security:         czSecurity,
		})
	t.logger = prefixLoggerForClientTransport(t)
	// Add peer information to the http2client context.
	t.ctx = peer.NewContext(t.ctx, t.getPeer())

	if md, ok := addr.Metadata.(*metadata.MD); ok {
		t.md = *md
	} else if md := imetadata.Get(addr); md != nil {
		t.md = md
	}
	t.controlBuf = newControlBuffer(t.ctxDone)
	if opts.InitialWindowSize >= defaultWindowSize {
		t.initialWindowSize = opts.InitialWindowSize
	}
	if !opts.StaticWindowSize {
		t.bdpEst = &bdpEstimator{
			bdp:               initialWindowSize,
			updateFlowControl: t.updateFlowControl,
		}
	}
	for _, sh := range t.statsHandlers {
		t.ctx = sh.TagConn(t.ctx, &stats.ConnTagInfo{
			RemoteAddr: t.remoteAddr,
			LocalAddr:  t.localAddr,
		})
		connBegin := &stats.ConnBegin{
			Client: true,
		}
		sh.HandleConn(t.ctx, connBegin)
	}
	if t.keepaliveEnabled {
		t.kpDormancyCond = sync.NewCond(&t.mu)
		go t.keepalive()
	}

	// Start the reader goroutine for incoming messages. Each transport has a
	// dedicated goroutine which reads HTTP2 frames from the network. Then it
	// dispatches the frame to the corresponding stream entity.  When the
	// server preface is received, readerErrCh is closed.  If an error occurs
	// first, an error is pushed to the channel.  This must be checked before
	// returning from this function.
	readerErrCh := make(chan error, 1)
	go t.reader(readerErrCh)
	defer func() {
		if err != nil {
			// writerDone should be closed since the loopy goroutine
			// wouldn't have started in the case this function returns an error.
			close(t.writerDone)
			t.Close(err)
		}
	}()

	// Send connection preface to server.
	n, err := t.conn.Write(clientPreface)
	if err != nil {
		err = connectionErrorf(true, err, "transport: failed to write client preface: %v", err)
		return nil, err
	}
	if n != len(clientPreface) {
		err = connectionErrorf(true, nil, "transport: preface mismatch, wrote %d bytes; want %d", n, len(clientPreface))
		return nil, err
	}
	var ss []http2.Setting

	if t.initialWindowSize != defaultWindowSize {
		ss = append(ss, http2.Setting{
			ID:  http2.SettingInitialWindowSize,
			Val: uint32(t.initialWindowSize),
		})
	}
	if opts.MaxHeaderListSize != nil {
		ss = append(ss, http2.Setting{
			ID:  http2.SettingMaxHeaderListSize,
			Val: *opts.MaxHeaderListSize,
		})
	}
	err = t.framer.fr.WriteSettings(ss...)
	if err != nil {
		err = connectionErrorf(true, err, "transport: failed to write initial settings frame: %v", err)
		return nil, err
	}
	// Adjust the connection flow control window if needed.
	if delta := uint32(icwz - defaultWindowSize); delta > 0 {
		if err := t.framer.fr.WriteWindowUpdate(0, delta); err != nil {
			err = connectionErrorf(true, err, "transport: failed to write window update: %v", err)
			return nil, err
		}
	}

	t.connectionID = atomic.AddUint64(&clientConnectionCounter, 1)

	if err := t.framer.writer.Flush(); err != nil {
		return nil, err
	}
	// Block until the server preface is received successfully or an error occurs.
	if err = <-readerErrCh; err != nil {
		return nil, err
	}
	go func() {
		t.loopy = newLoopyWriter(clientSide, t.framer, t.controlBuf, t.bdpEst, t.conn, t.logger, t.outgoingGoAwayHandler, t.bufferPool)
		if err := t.loopy.run(); !isIOError(err) {
			// Immediately close the connection, as the loopy writer returns
			// when there are no more active streams and we were draining (the
			// server sent a GOAWAY).  For I/O errors, the reader will hit it
			// after draining any remaining incoming data.
			t.conn.Close()
		}
		close(t.writerDone)
	}()
	return t, nil
}è¿™æ®µä»£ç æ˜¯å¦è¯´æ˜å®¢æˆ·ç«¯ä¼šè‡ªå·±æ§åˆ¶å¹¶å‘æ•°é‡	defaultMaxStreamsClient       = 100

çœŸç›¸ï¼š

1. ä»£ç é‡Œçš„ defaultMaxStreamsClient = 100
åœ¨ gRPC-Go (transport/http2_client.go) ç¡®å®å®šä¹‰äº†è¿™ä¸ªå¸¸é‡ï¼š

go

const defaultMaxStreamsClient = 100
åœ¨ä½ è´´çš„ NewHTTP2Client é‡Œï¼Œå®ƒè¢«èµ‹å€¼ç»™ï¼š

go

maxConcurrentStreams:  defaultMaxStreamsClient,
streamQuota:           defaultMaxStreamsClient,
è¿™çœ‹ä¸Šå»åƒæ˜¯â€œå®¢æˆ·ç«¯è‡ªå·±é»˜è®¤æœ€å¤šåªèƒ½å¹¶å‘ 100 ä¸ª streamâ€ã€‚

2. å®é™…è¿è¡Œæ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ
æ³¨æ„ï¼šè¿™åªæ˜¯ åˆå§‹å€¼ï¼Œå¹¶ä¸æ˜¯æœ€ç»ˆå€¼ã€‚

å½“å®¢æˆ·ç«¯å®Œæˆ HTTP/2 SETTINGS äº¤æ¢ ä¹‹åï¼ŒæœåŠ¡ç«¯ä¼šå‘Šè¯‰å®¢æˆ·ç«¯ï¼š
SETTINGS_MAX_CONCURRENT_STREAMS = N

åœ¨ gRPC-Go çš„ reader goroutine é‡Œï¼Œå½“æ”¶åˆ° SETTINGS å¸§æ—¶ï¼Œä¼šæ›´æ–°ï¼š

go
t.maxConcurrentStreams = srvSettings.MaxConcurrentStreams
t.streamQuota = srvSettings.MaxConcurrentStreams
æ‰€ä»¥ï¼š

åœ¨è¿æ¥åˆšå»ºç«‹ï¼Œè¿˜æ²¡æ”¶åˆ°æœåŠ¡ç«¯ SETTINGS ä¹‹å‰ï¼Œå®¢æˆ·ç«¯åªèƒ½å¼€ 100 ä¸ª streamã€‚

ä¸€æ—¦æ”¶åˆ°æœåŠ¡ç«¯çš„è®¾ç½®ï¼Œå°±ä¼šè¦†ç›–è¿™ä¸ªå€¼ã€‚

gRPC-Go æœåŠ¡ç«¯é»˜è®¤ä¸‹å‘çš„æ˜¯ math.MaxUint32 â‰ˆ 4e9ï¼Œä½†æ˜¯ä¼šè¢« HTTP/2 åè®®è§„èŒƒé™åˆ¶åœ¨ 2^31-1ï¼Œæ‰€ä»¥å¸¸è§å€¼æ˜¯ 65535ã€‚

3. ç»“åˆå®éªŒ
å®¢æˆ·ç«¯èµ·äº† 10000 ä¸ªå¹¶å‘è¯·æ±‚ï¼Œä¸€æ¬¡å°±å…¨è·‘å®Œäº†ï¼Œè€—æ—¶ 1sã€‚
è¯´æ˜ï¼š

å®¢æˆ·ç«¯åœ¨å»ºç«‹è¿æ¥åå·²ç»æ”¶åˆ°äº†æœåŠ¡ç«¯çš„ SETTINGSã€‚

æœåŠ¡ç«¯é»˜è®¤å€¼å¾ˆå¤§ï¼ˆ65535ï¼‰ï¼Œæ‰€ä»¥å®¢æˆ·ç«¯æ”¾å¼€äº†é™åˆ¶ã€‚

defaultMaxStreamsClient = 100 çš„å½±å“åªå­˜åœ¨äºã€Œåˆšè¿ä¸Šã€æ²¡æ¡æ‰‹å®Œã€çš„é‚£ä¸€ç¬é—´ã€‚ä½ æµ‹çš„æ—¶å€™å·²ç»è¿‡äº†è¿™ä¸€æ­¥ï¼Œæ‰€ä»¥ 100 å¹¶æ²¡æœ‰èµ·ä½œç”¨ã€‚

4. ç»“è®º
å®¢æˆ·ç«¯ç¡®å®æœ‰é»˜è®¤å¹¶å‘ä¸Šé™ 100ï¼Œä½†åªæ˜¯ ä¸´æ—¶çš„ bootstrap å€¼ã€‚

çœŸæ­£å†³å®šå¹¶å‘ä¸Šé™çš„æ˜¯ æœåŠ¡ç«¯å‘ä¸‹æ¥çš„ SETTINGS_MAX_CONCURRENT_STREAMSã€‚

gRPC-Go æœåŠ¡ç«¯é»˜è®¤ç»™å®¢æˆ·ç«¯çš„æ˜¯ä¸€ä¸ªå·¨å¤§çš„æ•°ï¼ˆ65535ï¼‰ï¼Œæ‰€ä»¥ä½ èƒ½å¹¶å‘ 300 ç”šè‡³æ›´å¤šã€‚

âœ… æ€»ç»“
ä½ çœ‹åˆ°çš„ defaultMaxStreamsClient = 100 å¹¶ä¸æ˜¯å®¢æˆ·ç«¯çš„ç¡¬é™åˆ¶ï¼Œè€Œæ˜¯ã€Œæ¡æ‰‹å®Œæˆå‰çš„å ä½å€¼ã€ã€‚
æœ€ç»ˆä¸Šé™å–å†³äºæœåŠ¡ç«¯ â€”â€” gRPC-Go æœåŠ¡ç«¯é»˜è®¤ä¸‹å‘ 65535ï¼Œæ‰€ä»¥ä½ å®éªŒé‡Œæ²¡æœ‰è¢«å¡ä½ã€‚

å…·ä½“ä»£ç åœ¨è¿™ï¼š
func (t *http2Client) handleSettings(f *http2.SettingsFrame, isFirst bool) {
	if f.IsAck() {
		return
	}
	var maxStreams *uint32
	var ss []http2.Setting
	var updateFuncs []func()
	f.ForeachSetting(func(s http2.Setting) error {
		switch s.ID {
		case http2.SettingMaxConcurrentStreams:
			maxStreams = new(uint32)
			*maxStreams = s.Val
		case http2.SettingMaxHeaderListSize:
			updateFuncs = append(updateFuncs, func() {
				t.maxSendHeaderListSize = new(uint32)
				*t.maxSendHeaderListSize = s.Val
			})
		default:
			ss = append(ss, s)
		}
		return nil
	})
	if isFirst && maxStreams == nil {
		maxStreams = new(uint32)
		*maxStreams = math.MaxUint32
	}
	sf := &incomingSettings{
		ss: ss,
	}
	if maxStreams != nil {
		updateStreamQuota := func() {
			delta := int64(*maxStreams) - int64(t.maxConcurrentStreams)
			t.maxConcurrentStreams = *maxStreams
			t.streamQuota += delta
			if delta > 0 && t.waitingStreams > 0 {
				close(t.streamsQuotaAvailable) // wake all of them up.
				t.streamsQuotaAvailable = make(chan struct{}, 1)
			}
		}
		updateFuncs = append(updateFuncs, updateStreamQuota)
	}
	t.controlBuf.executeAndPut(func() bool {
		for _, f := range updateFuncs {
			f()
		}
		return true
	}, sf)
}


è¿™æ®µ handleSettings æ­£æ˜¯ å®¢æˆ·ç«¯æ›´æ–°å¹¶å‘ä¸Šé™ çš„æ ¸å¿ƒé€»è¾‘ã€‚æˆ‘ä»¬æ‹†ä¸€ä¸‹ï¼š

1. å…³é”®ç‚¹ï¼šhttp2.SettingMaxConcurrentStreams
go

f.ForeachSetting(func(s http2.Setting) error {
    switch s.ID {
    case http2.SettingMaxConcurrentStreams:
        maxStreams = new(uint32)
        *maxStreams = s.Val
è¿™é‡Œä¼šæ•è·æœåŠ¡ç«¯ä¸‹å‘çš„ SETTINGS_MAX_CONCURRENT_STREAMS å€¼ã€‚

2. å¦‚æœæ˜¯ç¬¬ä¸€ä¸ª SETTINGSï¼Œä¸”æœåŠ¡ç«¯æ²¡æ˜¾å¼ç»™å€¼
go

if isFirst && maxStreams == nil {
    maxStreams = new(uint32)
    *maxStreams = math.MaxUint32
}
ğŸ“Œ è¿™è¯´æ˜ï¼š

ç¬¬ä¸€æ¬¡æ¡æ‰‹å¦‚æœæœåŠ¡ç«¯æ²¡å‘Šè¯‰å®¢æˆ·ç«¯å¹¶å‘ä¸Šé™ï¼Œé‚£å®¢æˆ·ç«¯å°±å‡è®¾ æ— é™å¤§ (2^32-1)ã€‚

è¿™ä¹Ÿè§£é‡Šäº†ä¸ºä»€ä¹ˆä½ å®éªŒé‡Œèƒ½è½»æ¾è¶…è¿‡ 100 â€”â€” gRPC-Go æœåŠ¡ç«¯é»˜è®¤ä¸ä¼šä¸‹å‘é™åˆ¶ã€‚

3. æ›´æ–°å¹¶å‘æ§åˆ¶
go
updateStreamQuota := func() {
    delta := int64(*maxStreams) - int64(t.maxConcurrentStreams)
    t.maxConcurrentStreams = *maxStreams
    t.streamQuota += delta
    if delta > 0 && t.waitingStreams > 0 {
        close(t.streamsQuotaAvailable) // wake all of them up.
        t.streamsQuotaAvailable = make(chan struct{}, 1)
    }
}
t.maxConcurrentStreamsï¼šæ›´æ–°ä¸ºæ–°çš„æœ€å¤§å¹¶å‘ã€‚

t.streamQuotaï¼šå¢åŠ å¯ç”¨çš„ stream é…é¢ã€‚

å¦‚æœæœ‰ç­‰å¾…ä¸­çš„ streamï¼Œå°±è¢«å”¤é†’ã€‚

4. ç»“åˆå‰é¢ä½ è´´çš„ defaultMaxStreamsClient = 100
è¿æ¥åˆšå»ºç«‹æ—¶ï¼Œå®¢æˆ·ç«¯ç”¨ ä¸´æ—¶å€¼ 100 é™åˆ¶å¹¶å‘ã€‚

ä¸€æ—¦æ”¶åˆ°æœåŠ¡ç«¯ SETTINGSï¼Œè¿™é‡Œçš„é€»è¾‘ä¼šç«‹åˆ»è¦†ç›–å®ƒã€‚

å¦‚æœæœåŠ¡ç«¯ä¸å‘ SETTINGS_MAX_CONCURRENT_STREAMSï¼Œå°±èµ°é»˜è®¤çš„ math.MaxUint32ï¼ˆå‡ ä¹æ— é™ï¼‰ã€‚

âœ… ç»“è®º
æ˜¯çš„ï¼Œå°±æ˜¯è¿™æ®µä»£ç æ§åˆ¶äº† gRPC å®¢æˆ·ç«¯æœ€ç»ˆèƒ½å¼€çš„å¹¶å‘æ•°ã€‚
defaultMaxStreamsClient = 100 åªæ˜¯åˆå§‹ bootstrap å€¼ï¼Œæ¡æ‰‹åä¼šè¢«è¿™é‡Œæ›¿æ¢æ‰ï¼Œæ‰€ä»¥ä½ çš„å®éªŒæ‰èƒ½è¶…è¿‡ 100ã€‚

